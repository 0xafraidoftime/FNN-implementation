{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PART - A\n",
        "\n",
        "1. Initialize Network\n",
        "2. Forward Propagation\n",
        "3. Compute Loss\n",
        "4. Backpropagation\n",
        "5. Update Parameters\n",
        "6. Training Loop\n",
        "7. Model Evaluation"
      ],
      "metadata": {
        "id": "47iYR0IeKIX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOU88p-zHaSV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import seaborn as sns\n",
        "\n",
        "class FFNN:\n",
        "    def __init__(self, layer_sizes, activations):\n",
        "        \"\"\"\n",
        "        Initialize the neural network\n",
        "        layer_sizes: list of integers representing neurons in each layer\n",
        "        activations: list of activation functions for each layer\n",
        "        \"\"\"\n",
        "        if len(layer_sizes) != len(activations) + 1:\n",
        "            raise ValueError(\"Number of activation functions must be equal to number of layers - 1\")\n",
        "\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.activations = activations\n",
        "        self.parameters = self.initialize_parameters()\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        \"\"\"\n",
        "        Initialize weights and biases\n",
        "        Returns: dictionary containing parameters\n",
        "        \"\"\"\n",
        "        parameters = {}\n",
        "        L = len(self.layer_sizes)\n",
        "\n",
        "        for l in range(1, L):\n",
        "            parameters[f'W{l}'] = np.random.randn(self.layer_sizes[l],\n",
        "                self.layer_sizes[l-1]) * np.sqrt(2.0 / self.layer_sizes[l-1])  # He initialization\n",
        "            parameters[f'b{l}'] = np.zeros((self.layer_sizes[l], 1))\n",
        "\n",
        "        return parameters\n",
        "\n",
        "    def sigmoid(self, Z):\n",
        "        \"\"\"Sigmoid activation function\"\"\"\n",
        "        A = 1 / (1 + np.exp(-Z))\n",
        "        return A, Z\n",
        "\n",
        "    def relu(self, Z):\n",
        "        \"\"\"ReLU activation function\"\"\"\n",
        "        A = np.maximum(0, Z)\n",
        "        return A, Z\n",
        "\n",
        "    def tanh(self, Z):\n",
        "        \"\"\"Tanh activation function\"\"\"\n",
        "        A = np.tanh(Z)\n",
        "        return A, Z\n",
        "\n",
        "    def softmax(self, Z):\n",
        "        \"\"\"Softmax activation function\"\"\"\n",
        "        exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "        A = exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
        "        return A, Z\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        \"\"\"\n",
        "        Forward propagation step\n",
        "        X: input data\n",
        "        Returns: output probabilities and cache of intermediate values\n",
        "        \"\"\"\n",
        "        caches = []\n",
        "        A = X\n",
        "        L = len(self.parameters) // 2\n",
        "\n",
        "        for l in range(1, L+1):\n",
        "            A_prev = A\n",
        "            W = self.parameters[f'W{l}']\n",
        "            b = self.parameters[f'b{l}']\n",
        "            Z = np.dot(W, A_prev) + b\n",
        "\n",
        "            if l == L:  # Output layer\n",
        "                A, _ = self.softmax(Z)\n",
        "            else:  # Hidden layers\n",
        "                if self.activations[l-1] == \"sigmoid\":\n",
        "                    A, _ = self.sigmoid(Z)\n",
        "                elif self.activations[l-1] == \"relu\":\n",
        "                    A, _ = self.relu(Z)\n",
        "                elif self.activations[l-1] == \"tanh\":\n",
        "                    A, _ = self.tanh(Z)\n",
        "\n",
        "            cache = (A_prev, W, b, Z, A)\n",
        "            caches.append(cache)\n",
        "\n",
        "        return A, caches\n",
        "\n",
        "    def compute_loss(self, Y, A):\n",
        "        \"\"\"\n",
        "        Compute cross-entropy loss\n",
        "        Y: true labels (one-hot encoded)\n",
        "        A: predicted probabilities\n",
        "        \"\"\"\n",
        "        m = Y.shape[1]\n",
        "        epsilon = 1e-15\n",
        "        A = np.clip(A, epsilon, 1 - epsilon)\n",
        "        return -np.sum(Y * np.log(A)) / m\n",
        "\n",
        "    def backward_propagation(self, X, Y, caches):\n",
        "        \"\"\"\n",
        "        Backward propagation step\n",
        "        Returns: gradients\n",
        "        \"\"\"\n",
        "        grads = {}\n",
        "        L = len(caches)\n",
        "        m = Y.shape[1]\n",
        "\n",
        "        # Output layer\n",
        "        current_cache = caches[L-1]\n",
        "        A_prev, W, b, Z, A = current_cache\n",
        "        dZ = A - Y\n",
        "\n",
        "        grads[f'dW{L}'] = np.dot(dZ, A_prev.T) / m\n",
        "        grads[f'db{L}'] = np.sum(dZ, axis=1, keepdims=True) / m\n",
        "        dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "        # Hidden layers\n",
        "        for l in reversed(range(L-1)):\n",
        "            current_cache = caches[l]\n",
        "            A_prev, W, b, Z, A = current_cache\n",
        "\n",
        "            if self.activations[l] == \"sigmoid\":\n",
        "                dZ = dA_prev * A * (1 - A)\n",
        "            elif self.activations[l] == \"relu\":\n",
        "                dZ = dA_prev * (Z > 0)\n",
        "            elif self.activations[l] == \"tanh\":\n",
        "                dZ = dA_prev * (1 - np.power(A, 2))\n",
        "\n",
        "            grads[f'dW{l+1}'] = np.dot(dZ, A_prev.T) / m\n",
        "            grads[f'db{l+1}'] = np.sum(dZ, axis=1, keepdims=True) / m\n",
        "            if l > 0:\n",
        "                dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def update_parameters(self, grads, learning_rate):\n",
        "        \"\"\"\n",
        "        Update network parameters using gradient descent\n",
        "        \"\"\"\n",
        "        L = len(self.parameters) // 2\n",
        "\n",
        "        for l in range(L):\n",
        "            self.parameters[f'W{l+1}'] -= learning_rate * grads[f'dW{l+1}']\n",
        "            self.parameters[f'b{l+1}'] -= learning_rate * grads[f'db{l+1}']\n",
        "\n",
        "    def compute_accuracy(self, Y, A):\n",
        "        \"\"\"Calculate prediction accuracy\"\"\"\n",
        "        predictions = np.argmax(A, axis=0)\n",
        "        true_labels = np.argmax(Y, axis=0)\n",
        "        return np.mean(predictions == true_labels)\n",
        "\n",
        "    def train(self, X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, batch_size=32):\n",
        "        \"\"\"\n",
        "        Train the neural network\n",
        "        Returns: history of loss and accuracy values\n",
        "        \"\"\"\n",
        "        history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'test_acc': []\n",
        "        }\n",
        "\n",
        "        m = X_train.shape[1]\n",
        "        n_batches = m // batch_size\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_loss = 0\n",
        "\n",
        "            # Shuffle the data\n",
        "            permutation = np.random.permutation(m)\n",
        "            X_shuffled = X_train[:, permutation]\n",
        "            Y_shuffled = Y_train[:, permutation]\n",
        "\n",
        "            for i in range(n_batches):\n",
        "                # Get mini-batch\n",
        "                start_idx = i * batch_size\n",
        "                end_idx = start_idx + batch_size\n",
        "                X_batch = X_shuffled[:, start_idx:end_idx]\n",
        "                Y_batch = Y_shuffled[:, start_idx:end_idx]\n",
        "\n",
        "                # Forward propagation\n",
        "                A, caches = self.forward_propagation(X_batch)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = self.compute_loss(Y_batch, A)\n",
        "                epoch_loss += loss\n",
        "\n",
        "                # Backward propagation\n",
        "                grads = self.backward_propagation(X_batch, Y_batch, caches)\n",
        "\n",
        "                # Update parameters\n",
        "                self.update_parameters(grads, learning_rate)\n",
        "\n",
        "            # Calculate epoch metrics\n",
        "            A_train, _ = self.forward_propagation(X_train)\n",
        "            train_acc = self.compute_accuracy(Y_train, A_train)\n",
        "\n",
        "            A_test, _ = self.forward_propagation(X_test)\n",
        "            test_acc = self.compute_accuracy(Y_test, A_test)\n",
        "\n",
        "            # Store metrics\n",
        "            history['train_loss'].append(epoch_loss / n_batches)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            history['test_acc'].append(test_acc)\n",
        "\n",
        "            if epoch % 5 == 0:\n",
        "                print(f\"Epoch {epoch}: Loss = {epoch_loss/n_batches:.4f}, Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
        "\n",
        "        return history\n",
        "\n",
        "def load_mnist_data():\n",
        "    \"\"\"Load and preprocess MNIST dataset\"\"\"\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Reshape and normalize\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1).T / 255.0\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1).T / 255.0\n",
        "\n",
        "    # One-hot encode labels\n",
        "    Y_train = np.eye(10)[y_train].T\n",
        "    Y_test = np.eye(10)[y_test].T\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training metrics\"\"\"\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'])\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train')\n",
        "    plt.plot(history['test_acc'], label='Test')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare MNIST data\n",
        "X_train, Y_train, X_test, Y_test = load_mnist_data()\n",
        "\n",
        "# Create network with proper dimensions\n",
        "layer_sizes = [784, 128, 64, 10]  # Must end with 10 for MNIST's 10 classes\n",
        "activations = [\"relu\", \"relu\", \"softmax\"]  # One activation per layer except input\n",
        "\n",
        "# Create and train the model\n",
        "model = FFNN(layer_sizes, activations)\n",
        "history = model.train(\n",
        "    X_train, Y_train,\n",
        "    X_test, Y_test,\n",
        "    learning_rate=0.01,\n",
        "    num_epochs=50,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "lkFR7-X7Hr6J",
        "outputId": "1e6a3f9e-b030-431d-a633-f634836573a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 0: Loss = 0.5488, Train Acc = 0.9091, Test Acc = 0.9124\n",
            "Epoch 5: Loss = 0.1542, Train Acc = 0.9589, Test Acc = 0.9542\n",
            "Epoch 10: Loss = 0.0996, Train Acc = 0.9728, Test Acc = 0.9667\n",
            "Epoch 15: Loss = 0.0719, Train Acc = 0.9810, Test Acc = 0.9710\n",
            "Epoch 20: Loss = 0.0547, Train Acc = 0.9864, Test Acc = 0.9741\n",
            "Epoch 25: Loss = 0.0426, Train Acc = 0.9902, Test Acc = 0.9751\n",
            "Epoch 30: Loss = 0.0331, Train Acc = 0.9928, Test Acc = 0.9757\n",
            "Epoch 35: Loss = 0.0260, Train Acc = 0.9948, Test Acc = 0.9757\n",
            "Epoch 40: Loss = 0.0209, Train Acc = 0.9959, Test Acc = 0.9772\n",
            "Epoch 45: Loss = 0.0168, Train Acc = 0.9979, Test Acc = 0.9775\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B Task 1 Activation function Analysis\n"
      ],
      "metadata": {
        "id": "TtucRmsBLISv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 - Task 1: Activation Function Analysis\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm  # For progress bars\n",
        "\n",
        "class ActivationAnalyzer:\n",
        "    def __init__(self, input_dim=784, output_dim=10):\n",
        "        \"\"\"\n",
        "        Initialize analyzer for 5-layer FFNN with different activation functions\n",
        "        \"\"\"\n",
        "        self.layer_sizes = [input_dim, 256, 128, 64, 32, output_dim]\n",
        "        self.activation_types = [\"sigmoid\", \"relu\", \"tanh\"]\n",
        "        self.activation_values = {}  # Store activation values for analysis\n",
        "\n",
        "    def create_5layer_network(self, activation_type):\n",
        "        \"\"\"\n",
        "        Create 5-layer FFNN with specified activation\n",
        "        \"\"\"\n",
        "        # All hidden layers use the specified activation, output layer uses softmax\n",
        "        activations = [activation_type] * 4 + [\"softmax\"]\n",
        "        return FFNN(self.layer_sizes, activations)\n",
        "\n",
        "    def collect_activations(self, model, X):\n",
        "        \"\"\"\n",
        "        Collect activation values from all layers\n",
        "        \"\"\"\n",
        "        A, caches = model.forward_propagation(X)\n",
        "        activations = []\n",
        "\n",
        "        for cache in caches[:-1]:  # Exclude output layer\n",
        "            _, _, _, _, A = cache\n",
        "            activations.append(A.flatten())\n",
        "\n",
        "        return activations\n",
        "\n",
        "    def plot_activation_distributions(self, activation_values, activation_type):\n",
        "        \"\"\"\n",
        "        Plot histograms of activation values for each layer\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        for i, values in enumerate(activation_values):\n",
        "            plt.subplot(2, 2, i+1)\n",
        "            sns.histplot(values, bins=50)\n",
        "            plt.title(f'Layer {i+1} Activation Distribution\\n{activation_type}')\n",
        "            plt.xlabel('Activation Value')\n",
        "            plt.ylabel('Frequency')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_comparison_curves(self, histories):\n",
        "        \"\"\"\n",
        "        Plot loss and accuracy curves for different activation functions\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Loss curves\n",
        "        plt.subplot(1, 2, 1)\n",
        "        for act_type, history in histories.items():\n",
        "            plt.plot(history['train_loss'], label=act_type)\n",
        "        plt.title('Training Loss Comparison')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        # Accuracy curves\n",
        "        plt.subplot(1, 2, 2)\n",
        "        for act_type, history in histories.items():\n",
        "            plt.plot(history['test_acc'], label=act_type)\n",
        "        plt.title('Test Accuracy Comparison')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_final_accuracy_comparison(self, histories):\n",
        "        \"\"\"\n",
        "        Bar plot of final accuracy for each activation function\n",
        "        \"\"\"\n",
        "        final_accuracies = {act: hist['test_acc'][-1]\n",
        "                           for act, hist in histories.items()}\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.bar(final_accuracies.keys(), final_accuracies.values())\n",
        "        plt.title('Final Test Accuracy by Activation Function')\n",
        "        plt.xlabel('Activation Function')\n",
        "        plt.ylabel('Accuracy')\n",
        "        for i, v in enumerate(final_accuracies.values()):\n",
        "            plt.text(i, v, f'{v:.3f}', ha='center')\n",
        "        plt.show()\n",
        "\n",
        "    def analyze_activations(self, X_train, Y_train, X_test, Y_test):\n",
        "        \"\"\"\n",
        "        Run complete activation function analysis\n",
        "        \"\"\"\n",
        "        print(\"Starting activation function analysis...\")\n",
        "        histories = {}\n",
        "\n",
        "        for act_type in self.activation_types:\n",
        "            print(f\"\\nTraining network with {act_type} activation...\")\n",
        "\n",
        "            # Create and train network\n",
        "            model = self.create_5layer_network(act_type)\n",
        "            history = model.train(\n",
        "                X_train, Y_train,\n",
        "                X_test, Y_test,\n",
        "                learning_rate=0.01,\n",
        "                num_epochs=30,\n",
        "                batch_size=64\n",
        "            )\n",
        "            histories[act_type] = history\n",
        "\n",
        "            # Collect and plot activation distributions\n",
        "            print(f\"\\nAnalyzing {act_type} activation distributions...\")\n",
        "            activation_values = self.collect_activations(model, X_test[:, :100])\n",
        "            self.plot_activation_distributions(activation_values, act_type)\n",
        "\n",
        "        # Plot comparative analysis\n",
        "        print(\"\\nGenerating comparative analysis plots...\")\n",
        "        self.plot_comparison_curves(histories)\n",
        "        self.plot_final_accuracy_comparison(histories)\n",
        "\n",
        "        return histories\n",
        "\n",
        "# Function to run Task 1 analysis\n",
        "def run_activation_analysis(X_train, Y_train, X_test, Y_test):\n",
        "    \"\"\"\n",
        "    Run complete analysis for Task 1\n",
        "    \"\"\"\n",
        "    print(\"Part 2 - Task 1: Activation Function Analysis\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    analyzer = ActivationAnalyzer()\n",
        "    histories = analyzer.analyze_activations(X_train, Y_train, X_test, Y_test)\n",
        "\n",
        "    # Print summary findings\n",
        "    print(\"\\nSummary Findings:\")\n",
        "    print(\"-\" * 20)\n",
        "    for act_type, history in histories.items():\n",
        "        final_acc = history['test_acc'][-1]\n",
        "        final_loss = history['train_loss'][-1]\n",
        "        print(f\"{act_type}:\")\n",
        "        print(f\"  Final Test Accuracy: {final_acc:.4f}\")\n",
        "        print(f\"  Final Training Loss: {final_loss:.4f}\")"
      ],
      "metadata": {
        "id": "fvfOniyiz577"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B Task 2: Batch Normalization Analysis"
      ],
      "metadata": {
        "id": "nuy2L4VWz-ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 - Task 2: Batch Normalization Analysis\n",
        "class BatchNormLayer:\n",
        "    def __init__(self, num_features):\n",
        "        self.gamma = np.ones((num_features, 1))\n",
        "        self.beta = np.zeros((num_features, 1))\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "        # Running estimates\n",
        "        self.running_mean = np.zeros((num_features, 1))\n",
        "        self.running_var = np.ones((num_features, 1))\n",
        "\n",
        "    def forward(self, X, training=True):\n",
        "        if training:\n",
        "            mean = np.mean(X, axis=1, keepdims=True)\n",
        "            var = np.var(X, axis=1, keepdims=True)\n",
        "\n",
        "            # Update running estimates\n",
        "            self.running_mean = 0.9 * self.running_mean + 0.1 * mean\n",
        "            self.running_var = 0.9 * self.running_var + 0.1 * var\n",
        "        else:\n",
        "            mean = self.running_mean\n",
        "            var = self.running_var\n",
        "\n",
        "        X_norm = (X - mean) / np.sqrt(var + self.epsilon)\n",
        "        out = self.gamma * X_norm + self.beta\n",
        "\n",
        "        if training:\n",
        "            self.cache = (X, X_norm, mean, var)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        X, X_norm, mean, var = self.cache\n",
        "        m = X.shape[1]\n",
        "\n",
        "        dX_norm = dout * self.gamma\n",
        "        dvar = np.sum(dX_norm * (X - mean) * -0.5 * (var + self.epsilon)**(-1.5), axis=1, keepdims=True)\n",
        "        dmean = np.sum(dX_norm * -1/np.sqrt(var + self.epsilon), axis=1, keepdims=True)\n",
        "\n",
        "        dX = (dX_norm / np.sqrt(var + self.epsilon) +\n",
        "              2 * dvar * (X - mean) / m +\n",
        "              dmean / m)\n",
        "\n",
        "        self.dgamma = np.sum(dout * X_norm, axis=1, keepdims=True)\n",
        "        self.dbeta = np.sum(dout, axis=1, keepdims=True)\n",
        "\n",
        "        return dX\n",
        "\n",
        "class BatchNormAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.layer_sizes = [784, 256, 128, 64, 32, 10]\n",
        "\n",
        "    def create_networks(self):\n",
        "        \"\"\"Create networks with and without batch normalization\"\"\"\n",
        "        # Standard network\n",
        "        standard_net = FFNN(self.layer_sizes, [\"relu\"]*4 + [\"softmax\"])\n",
        "\n",
        "        # Network with batch norm\n",
        "        bn_net = FFNN(self.layer_sizes, [\"relu\"]*4 + [\"softmax\"])\n",
        "        bn_net.batch_norm_layers = [BatchNormLayer(size) for size in self.layer_sizes[1:-1]]\n",
        "\n",
        "        return standard_net, bn_net\n",
        "\n",
        "    def plot_activation_distributions(self, standard_acts, bn_acts):\n",
        "        \"\"\"Plot activation distributions with and without batch norm\"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        for i in range(4):  # For each hidden layer\n",
        "            plt.subplot(2, 2, i+1)\n",
        "            sns.histplot(standard_acts[i], alpha=0.5, label='Standard', bins=50)\n",
        "            sns.histplot(bn_acts[i], alpha=0.5, label='BatchNorm', bins=50)\n",
        "            plt.title(f'Layer {i+1} Activation Distribution')\n",
        "            plt.xlabel('Activation Value')\n",
        "            plt.ylabel('Frequency')\n",
        "            plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_gradient_flow(self, standard_grads, bn_grads):\n",
        "        \"\"\"Plot gradient magnitudes across layers\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        layers = range(1, len(self.layer_sizes))\n",
        "        plt.plot(layers, standard_grads, 'o-', label='Standard')\n",
        "        plt.plot(layers, bn_grads, 'o-', label='BatchNorm')\n",
        "        plt.title('Gradient Magnitude Across Layers')\n",
        "        plt.xlabel('Layer')\n",
        "        plt.ylabel('Mean Gradient Magnitude')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_convergence_comparison(self, standard_history, bn_history):\n",
        "        \"\"\"Plot training curves for comparison\"\"\"\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Loss comparison\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(standard_history['train_loss'], label='Standard')\n",
        "        plt.plot(bn_history['train_loss'], label='BatchNorm')\n",
        "        plt.title('Training Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        # Accuracy comparison\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(standard_history['test_acc'], label='Standard')\n",
        "        plt.plot(bn_history['test_acc'], label='BatchNorm')\n",
        "        plt.title('Test Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def run_batchnorm_analysis(X_train, Y_train, X_test, Y_test):\n",
        "    \"\"\"Run complete analysis for Task 2\"\"\"\n",
        "    print(\"Part 2 - Task 2: Batch Normalization Analysis\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    analyzer = BatchNormAnalyzer()\n",
        "    standard_net, bn_net = analyzer.create_networks()\n",
        "\n",
        "    # Train both networks\n",
        "    print(\"\\nTraining standard network...\")\n",
        "    standard_history = standard_net.train(X_train, Y_train, X_test, Y_test,\n",
        "                                        learning_rate=0.01, num_epochs=30)\n",
        "\n",
        "    print(\"\\nTraining network with batch normalization...\")\n",
        "    bn_history = bn_net.train(X_train, Y_train, X_test, Y_test,\n",
        "                             learning_rate=0.01, num_epochs=30)\n",
        "\n",
        "    # Collect and analyze activations\n",
        "    standard_acts = standard_net.collect_activations(X_test[:, :100])\n",
        "    bn_acts = bn_net.collect_activations(X_test[:, :100])\n",
        "    analyzer.plot_activation_distributions(standard_acts, bn_acts)\n",
        "\n",
        "    # Analyze gradient flow\n",
        "    standard_grads = [np.mean(np.abs(g)) for g in standard_net.compute_gradients()]\n",
        "    bn_grads = [np.mean(np.abs(g)) for g in bn_net.compute_gradients()]\n",
        "    analyzer.plot_gradient_flow(standard_grads, bn_grads)\n",
        "\n",
        "    # Compare convergence\n",
        "    analyzer.plot_convergence_comparison(standard_history, bn_history)"
      ],
      "metadata": {
        "id": "qOhe8JZn0CnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B Task 3: Network Depth Analysis"
      ],
      "metadata": {
        "id": "fjQVZKIo0VXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 - Task 3: Network Depth Analysis\n",
        "class NetworkDepthAnalyzer:\n",
        "    def __init__(self, input_dim=784, output_dim=10):\n",
        "        \"\"\"\n",
        "        Analyzer for networks of different depths\n",
        "        depths: [3, 5, 7, 10] layers as specified in assignment\n",
        "        \"\"\"\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.depths = [3, 5, 7, 10]\n",
        "\n",
        "    def create_network_architecture(self, depth):\n",
        "        \"\"\"\n",
        "        Create layer sizes for network of specified depth\n",
        "        \"\"\"\n",
        "        if depth < 3:\n",
        "            raise ValueError(\"Depth must be at least 3 (input, hidden, output)\")\n",
        "\n",
        "        # Start with input and end with output\n",
        "        layer_sizes = [self.input_dim]\n",
        "\n",
        "        # Add hidden layers with gradually decreasing size\n",
        "        hidden_layers = depth - 2\n",
        "        start_size = 512\n",
        "        for i in range(hidden_layers):\n",
        "            layer_size = max(32, start_size // (2**i))  # Don't go below 32 neurons\n",
        "            layer_sizes.append(layer_size)\n",
        "\n",
        "        # Add output layer\n",
        "        layer_sizes.append(self.output_dim)\n",
        "\n",
        "        return layer_sizes\n",
        "\n",
        "    def plot_activation_distributions(self, activations_dict):\n",
        "        \"\"\"\n",
        "        Plot activation distributions for different network depths\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(20, 15))\n",
        "        for i, (depth, activations) in enumerate(activations_dict.items()):\n",
        "            plt.subplot(2, 2, i+1)\n",
        "            for j, layer_activations in enumerate(activations[1:-1]):  # Skip input and output\n",
        "                sns.kdeplot(layer_activations.flatten(), label=f'Layer {j+1}')\n",
        "            plt.title(f'{depth}-Layer Network Activations')\n",
        "            plt.xlabel('Activation Value')\n",
        "            plt.ylabel('Density')\n",
        "            plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_gradient_flow(self, gradient_dict):\n",
        "        \"\"\"\n",
        "        Plot gradient magnitudes across layers for different depths\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        for depth, gradients in gradient_dict.items():\n",
        "            layers = range(1, len(gradients) + 1)\n",
        "            plt.plot(layers, gradients, 'o-', label=f'{depth} layers')\n",
        "        plt.title('Gradient Magnitude Across Layers')\n",
        "        plt.xlabel('Layer')\n",
        "        plt.ylabel('Mean Gradient Magnitude')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_convergence_comparison(self, histories):\n",
        "        \"\"\"\n",
        "        Plot training curves for different network depths\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Loss comparison\n",
        "        plt.subplot(1, 2, 1)\n",
        "        for depth, history in histories.items():\n",
        "            plt.plot(history['train_loss'], label=f'{depth} layers')\n",
        "        plt.title('Training Loss by Network Depth')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        # Accuracy comparison\n",
        "        plt.subplot(1, 2, 2)\n",
        "        for depth, history in histories.items():\n",
        "            plt.plot(history['test_acc'], label=f'{depth} layers')\n",
        "        plt.title('Test Accuracy by Network Depth')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_final_metrics(self, histories):\n",
        "        \"\"\"\n",
        "        Plot final accuracy and convergence time for different depths\n",
        "        \"\"\"\n",
        "        depths = list(histories.keys())\n",
        "        accuracies = [hist['test_acc'][-1] for hist in histories.values()]\n",
        "\n",
        "        # Calculate epochs to reach 95% of final accuracy\n",
        "        convergence_epochs = []\n",
        "        for hist in histories.values():\n",
        "            final_acc = hist['test_acc'][-1]\n",
        "            threshold = 0.95 * final_acc\n",
        "            epochs_to_converge = next(\n",
        "                (i for i, acc in enumerate(hist['test_acc']) if acc >= threshold),\n",
        "                len(hist['test_acc'])\n",
        "            )\n",
        "            convergence_epochs.append(epochs_to_converge)\n",
        "\n",
        "        # Plot\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Accuracy plot\n",
        "        ax1.plot(depths, accuracies, 'o-')\n",
        "        ax1.set_title('Final Test Accuracy vs Network Depth')\n",
        "        ax1.set_xlabel('Number of Layers')\n",
        "        ax1.set_ylabel('Test Accuracy')\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Convergence time plot\n",
        "        ax2.plot(depths, convergence_epochs, 'o-')\n",
        "        ax2.set_title('Convergence Speed vs Network Depth')\n",
        "        ax2.set_xlabel('Number of Layers')\n",
        "        ax2.set_ylabel('Epochs to 95% Final Accuracy')\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def run_depth_analysis(X_train, Y_train, X_test, Y_test):\n",
        "    \"\"\"\n",
        "    Run complete analysis for Task 3\n",
        "    \"\"\"\n",
        "    print(\"Part 2 - Task 3: Network Depth Analysis\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    analyzer = NetworkDepthAnalyzer()\n",
        "    histories = {}\n",
        "    activations_dict = {}\n",
        "    gradient_dict = {}\n",
        "\n",
        "    for depth in analyzer.depths:\n",
        "        print(f\"\\nTraining {depth}-layer network...\")\n",
        "\n",
        "        # Create and train network\n",
        "        layer_sizes = analyzer.create_network_architecture(depth)\n",
        "        activations = [\"relu\"] * (depth-2) + [\"softmax\"]\n",
        "        model = FFNN(layer_sizes, activations)\n",
        "\n",
        "        history = model.train(\n",
        "            X_train, Y_train,\n",
        "            X_test, Y_test,\n",
        "            learning_rate=0.01,\n",
        "            num_epochs=30,\n",
        "            batch_size=64\n",
        "        )\n",
        "\n",
        "        histories[depth] = history\n",
        "\n",
        "        # Collect activations and gradients\n",
        "        print(f\"Analyzing {depth}-layer network...\")\n",
        "        A, caches = model.forward_propagation(X_test[:, :100])\n",
        "        activations_dict[depth] = [cache[4] for cache in caches]  # Get activation values\n",
        "\n",
        "        grads = model.backward_propagation(X_test[:, :100], Y_test[:, :100], caches)\n",
        "        gradient_dict[depth] = [np.mean(np.abs(g)) for g in grads.values()]\n",
        "\n",
        "    # Generate plots\n",
        "    print(\"\\nGenerating analysis plots...\")\n",
        "    analyzer.plot_activation_distributions(activations_dict)\n",
        "    analyzer.plot_gradient_flow(gradient_dict)\n",
        "    analyzer.plot_convergence_comparison(histories)\n",
        "    analyzer.plot_final_metrics(histories)\n",
        "\n",
        "    # Print summary findings\n",
        "    print(\"\\nSummary Findings:\")\n",
        "    print(\"-\" * 20)\n",
        "    for depth, history in histories.items():\n",
        "        final_acc = history['test_acc'][-1]\n",
        "        print(f\"{depth}-layer network:\")\n",
        "        print(f\"  Final Test Accuracy: {final_acc:.4f}\")"
      ],
      "metadata": {
        "id": "7mEUQl_O0V8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B Task 4: Weight Initialization Analysis"
      ],
      "metadata": {
        "id": "6x5SRsov0axf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 - Task 4: Weight Initialization Analysis\n",
        "class WeightInitializer:\n",
        "    @staticmethod\n",
        "    def random_init(prev_layer_size, current_layer_size):\n",
        "        \"\"\"Random initialization with small values\"\"\"\n",
        "        return np.random.randn(current_layer_size, prev_layer_size) * 0.01\n",
        "\n",
        "    @staticmethod\n",
        "    def xavier_init(prev_layer_size, current_layer_size):\n",
        "        \"\"\"Xavier/Glorot initialization\"\"\"\n",
        "        limit = np.sqrt(6 / (prev_layer_size + current_layer_size))\n",
        "        return np.random.uniform(-limit, limit, (current_layer_size, prev_layer_size))\n",
        "\n",
        "    @staticmethod\n",
        "    def he_init(prev_layer_size, current_layer_size):\n",
        "        \"\"\"He initialization\"\"\"\n",
        "        return np.random.randn(current_layer_size, prev_layer_size) * np.sqrt(2 / prev_layer_size)\n",
        "\n",
        "class InitializationAnalyzer:\n",
        "    def __init__(self, input_dim=784, output_dim=10):\n",
        "        \"\"\"\n",
        "        Analyzer for different weight initialization methods\n",
        "        \"\"\"\n",
        "        self.layer_sizes = [input_dim, 256, 128, 64, output_dim]\n",
        "        self.init_methods = {\n",
        "            \"Random\": WeightInitializer.random_init,\n",
        "            \"Xavier\": WeightInitializer.xavier_init,\n",
        "            \"He\": WeightInitializer.he_init\n",
        "        }\n",
        "\n",
        "    def create_network(self, init_method):\n",
        "        \"\"\"\n",
        "        Create network with specified initialization method\n",
        "        \"\"\"\n",
        "        model = FFNN(self.layer_sizes, [\"relu\"]*3 + [\"softmax\"])\n",
        "\n",
        "        # Override default initialization\n",
        "        L = len(self.layer_sizes)\n",
        "        for l in range(1, L):\n",
        "            model.parameters[f'W{l}'] = init_method(\n",
        "                self.layer_sizes[l-1],\n",
        "                self.layer_sizes[l]\n",
        "            )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def plot_initial_weight_distributions(self, models):\n",
        "        \"\"\"\n",
        "        Plot weight distributions after initialization\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        for i, (name, model) in enumerate(models.items(), 1):\n",
        "            plt.subplot(2, 2, i)\n",
        "            for l in range(1, len(self.layer_sizes)):\n",
        "                weights = model.parameters[f'W{l}'].flatten()\n",
        "                sns.histplot(weights, label=f'Layer {l}', bins=50)\n",
        "            plt.title(f'{name} Initialization')\n",
        "            plt.xlabel('Weight Value')\n",
        "            plt.ylabel('Frequency')\n",
        "            plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_activation_distributions(self, activation_dict):\n",
        "        \"\"\"\n",
        "        Plot activation distributions for different initialization methods\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        for i, (name, activations) in enumerate(activation_dict.items(), 1):\n",
        "            plt.subplot(2, 2, i)\n",
        "            for j, layer_activations in enumerate(activations[:-1]):  # Exclude output\n",
        "                sns.kdeplot(layer_activations.flatten(), label=f'Layer {j+1}')\n",
        "            plt.title(f'{name} Initialization - Activations')\n",
        "            plt.xlabel('Activation Value')\n",
        "            plt.ylabel('Density')\n",
        "            plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_gradient_flow(self, gradient_dict):\n",
        "        \"\"\"\n",
        "        Plot gradient magnitudes across layers\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for name, gradients in gradient_dict.items():\n",
        "            layers = range(1, len(gradients) + 1)\n",
        "            plt.plot(layers, gradients, 'o-', label=name)\n",
        "        plt.title('Gradient Magnitude Across Layers')\n",
        "        plt.xlabel('Layer')\n",
        "        plt.ylabel('Mean Gradient Magnitude')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_training_comparison(self, histories):\n",
        "        \"\"\"\n",
        "        Plot training curves for different initialization methods\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Loss comparison\n",
        "        plt.subplot(1, 2, 1)\n",
        "        for name, history in histories.items():\n",
        "            plt.plot(history['train_loss'], label=name)\n",
        "        plt.title('Training Loss by Initialization Method')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        # Accuracy comparison\n",
        "        plt.subplot(1, 2, 2)\n",
        "        for name, history in histories.items():\n",
        "            plt.plot(history['test_acc'], label=name)\n",
        "        plt.title('Test Accuracy by Initialization Method')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def run_initialization_analysis(X_train, Y_train, X_test, Y_test):\n",
        "    \"\"\"\n",
        "    Run complete analysis for Task 4\n",
        "    \"\"\"\n",
        "    print(\"Part 2 - Task 4: Weight Initialization Analysis\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    analyzer = InitializationAnalyzer()\n",
        "    models = {}\n",
        "    histories = {}\n",
        "    activation_dict = {}\n",
        "    gradient_dict = {}\n",
        "\n",
        "    # Create and initialize models\n",
        "    for name, init_method in analyzer.init_methods.items():\n",
        "        models[name] = analyzer.create_network(init_method)\n",
        "\n",
        "    # Plot initial weight distributions\n",
        "    print(\"\\nAnalyzing initial weight distributions...\")\n",
        "    analyzer.plot_initial_weight_distributions(models)\n",
        "\n",
        "    # Train models and collect data\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining model with {name} initialization...\")\n",
        "        history = model.train(\n",
        "            X_train, Y_train,\n",
        "            X_test, Y_test,\n",
        "            learning_rate=0.01,\n",
        "            num_epochs=30,\n",
        "            batch_size=64\n",
        "        )\n",
        "        histories[name] = history\n",
        "\n",
        "        # Collect activations and gradients\n",
        "        A, caches = model.forward_propagation(X_test[:, :100])\n",
        "        activation_dict[name] = [cache[4] for cache in caches]\n",
        "\n",
        "        grads = model.backward_propagation(X_test[:, :100], Y_test[:, :100], caches)\n",
        "        gradient_dict[name] = [np.mean(np.abs(g)) for g in grads.values()]\n",
        "\n",
        "    # Generate analysis plots\n",
        "    print(\"\\nGenerating analysis plots...\")\n",
        "    analyzer.plot_activation_distributions(activation_dict)\n",
        "    analyzer.plot_gradient_flow(gradient_dict)\n",
        "    analyzer.plot_training_comparison(histories)\n",
        "\n",
        "    # Print summary findings\n",
        "    print(\"\\nSummary Findings:\")\n",
        "    print(\"-\" * 20)\n",
        "    for name, history in histories.items():\n",
        "        final_acc = history['test_acc'][-1]\n",
        "        print(f\"{name} initialization:\")\n",
        "        print(f\"  Final Test Accuracy: {final_acc:.4f}\")"
      ],
      "metadata": {
        "id": "uYOoxZ7W0dOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}